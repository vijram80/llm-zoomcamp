{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36996515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "320f7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url='https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10862372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d45e1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm=df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8b65649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name='multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce71af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be20a1",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8730b650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244658"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ebe6f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0222a6ee64a7ba74e2364165b1101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "evaluations_llm = []\n",
    "evaluations_orig = []\n",
    "\n",
    "for i, doc in tqdm(df.iterrows()):\n",
    "        answer_llm = doc['answer_llm']\n",
    "        answer_orig = doc['answer_orig']\n",
    "        evaluations_llm.append(embedding_model.encode(answer_llm))\n",
    "        evaluations_orig.append(embedding_model.encode(answer_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e6439a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [np.dot(e1,e2) for e1, e2 in zip(evaluations_llm, evaluations_orig)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85aaf76",
   "metadata": {},
   "source": [
    "Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71515375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.674312114715576"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(scores, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6e754e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8474eb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a31e7a9d0b640778ff5c40a86325b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "evaluations_llm_norm = []\n",
    "evaluations_orig_norm = []\n",
    "\n",
    "for i, doc in tqdm(df.iterrows()):\n",
    "        answer_llm = doc['answer_llm']\n",
    "        answer_orig = doc['answer_orig']\n",
    "        evaluations_llm_norm.append(normalize(embedding_model.encode(answer_llm)))\n",
    "        evaluations_orig_norm.append(normalize(embedding_model.encode(answer_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1f46113",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_score = [np.dot(e1,e2) for e1, e2 in zip(evaluations_llm_norm, evaluations_orig_norm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d175fa",
   "metadata": {},
   "source": [
    "Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3fd72088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362347930669785"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(cosine_score, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38f0342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /home/vijay/anaconda3/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1aaf5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "rouge_scores = rouge_scorer.get_scores(df['answer_llm'], df['answer_orig'])[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebf0f8",
   "metadata": {},
   "source": [
    "Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7991ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878a693",
   "metadata": {},
   "source": [
    "Question 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f289791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rouge_score = (rouge_scores['rouge-1']['f'] + rouge_scores['rouge-2']['f'] + rouge_scores['rouge-l']['f']) / 3\n",
    "mean_rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b3f37b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cba094989b4bc394434cc3782d8fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "results = []\n",
    "\n",
    "for i, doc in tqdm(df.iterrows()):\n",
    "    rouge_score = rouge_scorer.get_scores(df['answer_llm'], df['answer_orig'])[i]\n",
    "    results.append({\n",
    "        'rouge1': rouge_score['rouge-1']['f'],\n",
    "        'rouge2': rouge_score['rouge-2']['f'],\n",
    "        'rougel': rouge_score['rouge-l']['f'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0eb27e",
   "metadata": {},
   "source": [
    "Question 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a670c060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df = pd.DataFrame(results)\n",
    "mean_rouge2 = r_df['rouge2'].mean()\n",
    "mean_rouge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36cc81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
